# 用python爬蟲模擬pixiv網站熱門搜尋功能之可行性
## 前言
本專案僅作為本人面試工作時展示作品之用，功能及介面還相當簡陋。  
如真的想要使用pixiv的熱門搜尋功能，建議還是直接買個會員比較快。
## 研究動機
pixiv是日本最大的ACG向創作者平台，其中包含插畫、漫畫、小說及3D建模等等的作品都可以上傳到這網站供大家欣賞，而使用者也可以使用網站內建的搜尋功能來搜尋自己想要的原創或二創作品。但對於這類型網站的搜尋功能最重要的由熱門排序卻是鎖起來的，必須要購買它們的付費會員才可以解鎖，雖然他一個月的費用不算太貴，但身為一個略懂python的程式新手，便想到是否可以使用爬蟲來模擬這個熱門搜尋的功能，便有了此專題的出現。
## 使用方法
打開pixiv_get或pixiv_web檔案，並修改最後一行程式碼。  
``` python3 
pixiv_get(keyword, page, rating_count)
```  
有三個參數可以輸入，第一個輸入關鍵字，第二個輸入要爬取頁數(未登入狀態僅能爬取十頁)，第三個輸入只顯示或下載多少收藏數以上的圖片。  
``` python3 
pixiv_get('cyberpunk',10 , 500)
```  
以上示為例，輸出的結果是爬取關鍵字是cyberpunk，前十頁收藏數超過500的圖片，並且由高到低排列。 
***
pixiv_get 此程式功能為將爬取到的插畫以原圖尺寸下載到download資料夾內。  
* 輸出結果:
<img src="img/image_2.PNG" width="50%">
  
***
pixiv_web 此程式功能為將爬取的內容以網站得方式呈現，每張圖點進去都會連結到該圖片的pixiv網站。  
* 輸出結果:
<img src="img/image.PNG" width="50%">  

## 撰寫過程使用及學習到的技術
雖然這次撰寫得只是程式在100行左右的小專題，但過程中還是遇到蠻多問題跟學到了不少東西，包刮以下:
* 用網頁的開發者模式正確爬取使用ajax動態輸入網站的資料。  
* 使用泡沫排序法將爬取到的資料由收藏數的高低作排序。  
* 運用純字串的方式將python程式的輸出結果以網頁的方式作呈現。  

## 結論
那這次用python爬蟲模擬pixiv網站熱門搜尋功能之可行性研究的結果，基本上要完全重現跟官網一樣的功能是幾乎不太可能的，而最大問題有以下兩點:  
* 第一個問題

判斷一張圖的熱門與否，應該是從那張圖的瀏覽數及收藏數還有按讚數來分辨。但這些資料並不會出現在搜尋的預覽圖網頁上，而是必須點進圖片本身才可以看到上述的內容。造成說假如搜尋結果總共有1000筆資料，那就要執行1000次的網頁請求，大大家爬蟲請求被官網拒絕的機率，當然這問題可以用隨機時間函數，跟複數的IP作請求來規避這個問題，而我的程式也運用了上述的兩種方法，確實可以解決這個問題，但那是在未登入的前提底下，假如在有登入的情況下便會產生第二個問題。  
* 第二個問題

pixiv網站的搜尋功能在未登入的情況下是有瀏覽限制的，也就是他只能顯示前十頁的作品，而要開啟十頁之後的內容則必須要作登入的動作，那以我自己的方法是直接實際開瀏覽器作登入的動作，在複製cookie來作為爬蟲網頁請求之用，便可以爬取到十頁之後的內容，但也會衍伸一個問題，因為每次請求cookie是固定，縱使有使用複數的IP，但實際上仍然是同個使用者ID在作請求，也就會發生第一個請求過於頻繁被拒絕的問題。  
那在我反覆測試之後，發現單獨傳送'PHPSESSID'的這個cookie可以正確地回傳回十頁之後的內容，推斷網站應該是以此來驗證登入者資料的。  
'PHPSESSID'的值實際如下:  
``` python 3
86311421_NuEO3zWe4jxdmIvpm9hTgHDf14yepyLr
```
前面的純數字是會員的ID，每個會員都有其固定的ID，而後面的亂數碼則是在你每次開啟他的網站時會生成給你，而在沒登入的情況下就只會生成後面的亂數碼的值，並在你關閉瀏覽器後失效。  
當你登入之後便會加在你的會員ID之後，作為此次登入並使用的證明，然後在你登出後失效，也就是說你無法單純使用複數的會員ID去作輪流的請求規避官網的流量限制，因為後面的亂數碼會驗證你的ID是否已用瀏覽器作登入的狀態。 

如果真的硬要破解這個問題，那只能準備好幾個帳號，然後作登入的動作並取出'PHPSESSID'的這個cookie值，並要同時保持登入的狀態下輪流用不同的cookie來請求資料規避官網的流量限制，但因為我沒那麼多的帳號，並且就算真的能爬取所有的內容，除了要花費大把時間跑程式，有些熱門的關鍵字少說都幾十萬甚至幾百萬筆作品，全部爬取下來也會對pixiv網站造成非常大的負擔。  

結論是以上程式比較適合爬取較冷門關鍵字的作品，差不多1000個上下的都還免強可以全部爬下來，那其實也可以搜尋單一角色而不是作品本身，或是多增加幾個關鍵字來縮小搜尋的範圍等等。  
那假如真的想要搜尋那種好幾十萬筆作品的關鍵字，那還是建議直接買會員比較快。
